<!DOCTYPE html>
<html lang="en-us">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<meta name="theme-color" content="#494f5c">
	<meta name="msapplication-TileColor" content="#494f5c">
<meta itemprop="name" content="Deep Learning Server Budget Build">
<meta itemprop="description" content="td { border-bottom: 1px groove #c7c8cb; border-top: 1px groove #c7c8cb; padding-left:20px; } table{ background-color:#2c3e5099; padding: 20px; font-size: 10pt; } img{ background-color:#2c3e5099; }  I was looking for a budget build workstation for deep learning model training. I decided that the system to start with should have the best price-to-flop performance, since my experience with the latest Titan V/Telsa V100 on Google Cloud is not very good. Training complex models are not significantly faster than the TitanXP in our lab.">


<meta itemprop="datePublished" content="2019-01-01T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-01-01T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="661">

  <meta itemprop="image" content="https://picsum.photos/1024/768/?image=0&blur">



<meta itemprop="keywords" content="DeepLearning,Hardware," />
<meta property="og:title" content="Deep Learning Server Budget Build" />
<meta property="og:description" content="td { border-bottom: 1px groove #c7c8cb; border-top: 1px groove #c7c8cb; padding-left:20px; } table{ background-color:#2c3e5099; padding: 20px; font-size: 10pt; } img{ background-color:#2c3e5099; }  I was looking for a budget build workstation for deep learning model training. I decided that the system to start with should have the best price-to-flop performance, since my experience with the latest Titan V/Telsa V100 on Google Cloud is not very good. Training complex models are not significantly faster than the TitanXP in our lab." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://stevending.net/posts/deeplearninghardware/" />
<meta property="og:image" content="https://picsum.photos/1024/768/?image=0&blur" />
<meta property="article:published_time" content="2019-01-01T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2019-01-01T00:00:00&#43;00:00"/>
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://picsum.photos/1024/768/?image=0&blur"/>

<meta name="twitter:title" content="Deep Learning Server Budget Build"/>
<meta name="twitter:description" content="td { border-bottom: 1px groove #c7c8cb; border-top: 1px groove #c7c8cb; padding-left:20px; } table{ background-color:#2c3e5099; padding: 20px; font-size: 10pt; } img{ background-color:#2c3e5099; }  I was looking for a budget build workstation for deep learning model training. I decided that the system to start with should have the best price-to-flop performance, since my experience with the latest Titan V/Telsa V100 on Google Cloud is not very good. Training complex models are not significantly faster than the TitanXP in our lab."/>
	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	<link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/favicon.ico">

	<title>Deep Learning Server Budget Build</title>
	<link rel="stylesheet" href="http://stevending.net/css/style.min.59ff758e1a1c11d20e1cb88344ad3db5a3df5fd34ee695965077aeefcc4c2e2a.css" integrity="sha256-Wf91jhocEdIOHLiDRK09taPfX9NO5pWWUHeu78xMLio=">
	<style>.bg-img {background-image: url('https://picsum.photos/1024/768/?image=0&blur');}</style>
</head>

<body id="page">
	
	<header id="site-header" class="">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="http://stevending.net">Steven Ding</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					<a href="http://stevending.net/about/">About</a>
					<a href="http://stevending.net/publications/">Publications</a>
					<a href="http://stevending.net/teaching/">Teaching</a>
					<a href="http://stevending.net/services/">Services</a>
					<a href="http://stevending.net/fundings/">Awards</a>
					<a href="http://stevending.net/mentorship/">Mentorship</a>
					<a href="http://stevending.net/posts/">Posts</a>
					<a href="http://stevending.net/schedule/">Schedule</a>
					<a href="http://stevending.net/contact/">Contact</a>
				</nav>
			</div>
			
			<div class="hdr-right hdr-icons">
				
				
				<button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="http://stevending.net/about/">About</a></li>
			<li><a href="http://stevending.net/publications/">Publications</a></li>
			<li><a href="http://stevending.net/teaching/">Teaching</a></li>
			<li><a href="http://stevending.net/services/">Services</a></li>
			<li><a href="http://stevending.net/fundings/">Awards</a></li>
			<li><a href="http://stevending.net/mentorship/">Mentorship</a></li>
			<li><a href="http://stevending.net/posts/">Posts</a></li>
			<li><a href="http://stevending.net/schedule/">Schedule</a></li>
			<li><a href="http://stevending.net/contact/">Contact</a></li>
		</ul>
	</div>


	<div class="bg-img"></div>
	<main class="site-main section-inner animated fadeIn faster">
		<article class="thin">
			<header class="post-header">
				<div class="post-meta"><span>Jan 1, 2019</span></div>
				<h1>Deep Learning Server Budget Build</h1>
			</header>
			<div class="content">
				<style>
td {
        border-bottom: 1px groove #c7c8cb;
        border-top: 1px groove #c7c8cb;
        padding-left:20px;
}

table{
    background-color:#2c3e5099;
    padding: 20px;
    font-size: 10pt;
}

img{
    background-color:#2c3e5099;
}
</style>

<p>I was looking for a budget build workstation for deep learning model training.
I decided that the system to start with should have the <strong><em>best price-to-flop performance</em></strong>, since my experience with the latest Titan V/Telsa V100 on Google Cloud is not very good. Training complex models are not significantly faster than the TitanXP in our lab.
It will still take some time for the major deep learning frameworks to fully exploit the advantages of the added Tensor Cores.
With the same budget, I can already get 4x1080ti which can significantly boost my training speed by data parallelization.
Belows are benchmarks and specs from <a href="https://github.com/u39kun/deep-learning-benchmark" target="_blank">Yusaku Sako</a>. My biased observation is that, <em>optimizing my code will make my models get trained faster than switching to the latest GPU for my use cases</em>.</p>

<p><center></p>

<table>
<thead>
<tr>
<th>Model</th>
<th>Architecture</th>
<th>Memory</th>
<th>CUDA</th>
<th>Tensor Cores</th>
<th>F32 TFLOPS</th>
<th>F16 TFLOPS</th>
<th>Cost</th>
</tr>
</thead>

<tbody>
<tr>
<td>Tesla V100</td>
<td>Volta</td>
<td>16GB HBM2</td>
<td>5120</td>
<td>640</td>
<td>15.7</td>
<td>125</td>
<td>$3.06/hr</td>
</tr>

<tr>
<td>Titan V</td>
<td>Volta</td>
<td>12GB HBM2</td>
<td>5120</td>
<td>640</td>
<td>15</td>
<td>110*</td>
<td>$2999</td>
</tr>

<tr>
<td>1080 Ti</td>
<td>Pascal</td>
<td>11GB GDDR5</td>
<td>3584</td>
<td>0</td>
<td>11</td>
<td>N/A</td>
<td>$699</td>
</tr>
</tbody>
</table>

<p></center></p>

<p>The benchmark below is taken from <a href="https://lambdalabs.com/blog/best-gpu-tensorflow-2080-ti-vs-v100-vs-titan-v-vs-1080-ti-benchmark/" target="_blank">Lambda Lab Benchmark</a>. Values represent the speed-up-against-1080ti/$1000 (F32). Again, for my use case this number should be much lower, since the GPU is not very well utilized.</p>

<table>
<thead>
<tr>
<th>Model/GPU</th>
<th>2080 Ti</th>
<th>Titan V</th>
<th>V100</th>
<th>1080 Ti</th>
</tr>
</thead>

<tbody>
<tr>
<td>Price Per GPU (k$)</td>
<td>1.2</td>
<td>3</td>
<td>9.8</td>
<td>0.7</td>
</tr>

<tr>
<td>Price Per 1 GPU System (k$)</td>
<td>2.49</td>
<td>4.29</td>
<td>11.09</td>
<td>1.99</td>
</tr>

<tr>
<td>AVG</td>
<td>0.55</td>
<td>0.33</td>
<td>0.16</td>
<td>0.5</td>
</tr>

<tr>
<td>ResNet-50</td>
<td>0.56</td>
<td>0.34</td>
<td>0.16</td>
<td>0.5</td>
</tr>

<tr>
<td>ResNet-152</td>
<td>0.53</td>
<td>0.31</td>
<td>0.14</td>
<td>0.5</td>
</tr>

<tr>
<td>InceptionV3</td>
<td>0.58</td>
<td>0.37</td>
<td>0.17</td>
<td>0.5</td>
</tr>

<tr>
<td>InceptionV4</td>
<td>0.57</td>
<td>0.32</td>
<td>0.14</td>
<td>0.5</td>
</tr>

<tr>
<td>VGG16</td>
<td>0.51</td>
<td>0.33</td>
<td>0.16</td>
<td>0.5</td>
</tr>

<tr>
<td>AlexNet</td>
<td>0.52</td>
<td>0.32</td>
<td>0.16</td>
<td>0.5</td>
</tr>

<tr>
<td>SSD300</td>
<td>0.55</td>
<td>0.33</td>
<td>0.16</td>
<td>0.5</td>
</tr>
</tbody>
</table>

<p>Then I came across the PC build of the <a href="https://pcpartpicker.com/list/mXFJd6" target="_blank">Lambda Lab build</a> and a customized build by <a href="https://ca.pcpartpicker.com/b/b9KBD3" target="_blank">kylemcdonald</a> on <a href="pcpartpicker.com" target="_blank">pcpartpicker.com</a>. I combine them as below:</p>

<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td>CPU</td>
<td>Intel - Core i7-6850K 3.6 GHz 6-Core Processor</td>
<td>$863.99</td>
</tr>

<tr>
<td>CPU Cooler</td>
<td>Intel - BXTS13A CPU Cooler</td>
<td>$21</td>
</tr>

<tr>
<td>Motherboard</td>
<td>Asus - X99-E WS/USB 3.1 SSI CEB LGA2011-3 Motherboard</td>
<td>$680.84</td>
</tr>

<tr>
<td>Memory</td>
<td>Corsair - Vengeance LPX 64 GB (4 x 16 GB) DDR4-2666 Memory</td>
<td>$612</td>
</tr>

<tr>
<td>Storage</td>
<td>Crucial - MX300 1.05 TB 2.5&rdquo; Solid State Drive</td>
<td>$341.99</td>
</tr>

<tr>
<td>Video Card</td>
<td>PNY 1080 T​i Founders​ Edition (or any blower-style 1080ti)</td>
<td></td>
</tr>

<tr>
<td></td>
<td>PNY 1080 T​i Founders​ Edition (or any blower-style 1080ti)</td>
<td></td>
</tr>

<tr>
<td></td>
<td>PNY 1080 T​i Founders​ Edition (or any blower-style 1080ti)</td>
<td></td>
</tr>

<tr>
<td></td>
<td>PNY 1080 T​i Founders​ Edition (or any blower-style 1080ti)</td>
<td></td>
</tr>

<tr>
<td>Case</td>
<td>Corsair - Carbide 400Q ATX Mid Tower Case</td>
<td>$164.74</td>
</tr>

<tr>
<td>Case</td>
<td>Carbide Se​ries® Air ​540 Arctic​ Black</td>
<td>$169.99</td>
</tr>

<tr>
<td>Power Supply</td>
<td>EVGA - SuperNOVA P2 1600 W 80+ Platinum Certified Fully-Modular ATX Power Supply</td>
<td>$347</td>
</tr>

<tr>
<td>Total</td>
<td></td>
<td>$3,201.55</td>
</tr>
</tbody>
</table>

<p>The total price above does not include the GPUs. The price of 1080ti varies depending on where you want to get one.
I will probably get those from e-Bay, so the cost can be significantly lower.
Based on the reviews, GPUs from e-Bay work fairly well for reasonable price.
Of course one needs to be cautious with those offers that are too good to be true.</p>

<p>Any 1080ti version that comes with a blower style thermal solution should be compatible:</p>

<figure>
    <img src="./1080ti.png"
         alt="image"/> <figcaption>
            <p>Asus GTX 1080ti Turbo</p>
        </figcaption>
</figure>


<p>The above setup is versatile, it can fit other NV-brand GPUs.
So I can upgrade my GPU later on.
That&rsquo;s why I still use brand-new parts for the other components.</p>

<p>It is noted that the CPU supports 40 PCIe lanes. Even though there will require 4*16 lanes for four GPUs,
the motherboard comes with a PLX switch that can simulate 16 lanes for each GPU.
So one can avoid the wired <code>16x8x8x8</code> setups.
However, <strong><em>the maximum bandwidth still limits to 40 lanes at the same moment</em></strong>.
This would be problematic for data parallelization, since we need to wait for the slowest GPU to finish before moving on the next step.
This problem cannot be fixed without a budget &lt; $20,000 (we need two CPUs).
For now I will just ignore this issue.</p>

			</div>
			<hr class="post-end">
			<footer class="post-info">
				<p>
					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="http://stevending.net/tags/deeplearning">DeepLearning</a></span><span class="tag"><a href="http://stevending.net/tags/hardware">Hardware</a></span>
				</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>661 Words</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2018-12-31 19:00 -0500</p>
			</footer>
		</article>
		<aside id="toc">
			<div class="toc-title">Table of Contents</div>
			
		</aside>
		<div class="post-nav thin">
		</div>
		<div id="comments" class="thin">
</div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p>&copy; 2019 <a href="http://stevending.net">Steven H. H. Ding</a></p>
		<a href="http://www.easycounter.com/"><img src="http://www.easycounter.com/counter.php?dingdanipp" border="0" alt="Free Hit Counter"></a>
		
	</footer>


	<script src="http://stevending.net/js/main.min.2405236001a8a985219a76eff5aa74e776ad317c13a0afb1246e088843a91335.js" integrity="sha256-JAUjYAGoqYUhmnbv9ap053atMXwToK+xJG4IiEOpEzU="></script>

	
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-77868521-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

</body>

</html>
